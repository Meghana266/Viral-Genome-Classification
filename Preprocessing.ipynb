{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a3d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the data- Converting Text file to CSV\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c9c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read FASTA file and return DNA sequences\n",
    "def read_fasta(filename):\n",
    "    sequences = []\n",
    "    additional_data = []  # Additional data for each sequence\n",
    "    with open(filename, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        sequence = \"\"\n",
    "        for line in lines:\n",
    "            if line.startswith(\">\"):\n",
    "                if sequence:\n",
    "                    sequences.append(sequence)\n",
    "                    sequence = \"\"\n",
    "                # Extract additional data from header (e.g., accession number, description)\n",
    "                header = line.strip().split(\"|\")\n",
    "                additional_data.append(header)\n",
    "            else:\n",
    "                sequence += line.strip()\n",
    "        if sequence:  # Add the last sequence\n",
    "            sequences.append(sequence)\n",
    "    return sequences, additional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e882ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_to_csv(input_filename, output_filename, label, disease_name):\n",
    "    sequences, additional_data = read_fasta(input_filename)\n",
    "    region_name = os.path.splitext(os.path.basename(input_filename))[0]\n",
    "    with open(output_filename, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # Define column headers\n",
    "        writer.writerow([\"DNA\", \"Region\", \"Length\", \"Disease\", \"Label\"])\n",
    "        for sequence, data in zip(sequences, additional_data):\n",
    "            sequence_length = len(sequence)\n",
    "            writer.writerow([sequence, region_name, sequence_length, disease_name, label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a3b370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main folder containing subfolders with FASTA files\n",
    "main_folder = \"Viral_Data_Sequences\"\n",
    "output_folder = \"Viral_Data_Csv\"\n",
    "\n",
    "# Define a dictionary to map folder names to disease names and labels\n",
    "disease_mapping = {\n",
    "    \"HBV\": {\"disease\": \"HBV\", \"label\": 0},\n",
    "    \"INFLUENZA\": {\"disease\": \"Influenza\", \"label\": 1},\n",
    "    \"HCV\": {\"disease\": \"HCV\", \"label\": 2},\n",
    "    \"DENGUE\": {\"disease\": \"Dengue\", \"label\": 3}\n",
    "}\n",
    "\n",
    "# Function to process a folder containing FASTA files\n",
    "def process_folder(folder_path, disease_name):\n",
    "    region_name = os.path.basename(folder_path)\n",
    "    output_subfolder = os.path.join(output_folder, region_name)\n",
    "    os.makedirs(output_subfolder, exist_ok=True)\n",
    "    label = disease_mapping[disease_name.upper()][\"label\"]\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".fasta\"):\n",
    "            input_file_path = os.path.join(folder_path, file_name)\n",
    "            output_file_path = os.path.join(output_subfolder, f\"{os.path.splitext(file_name)[0]}.csv\")\n",
    "            fasta_to_csv(input_file_path, output_file_path, label, region_name)\n",
    "\n",
    "# Function to recursively traverse the directory structure and process folders\n",
    "def process_folders(root_folder):\n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            if folder_name.upper() in disease_mapping:\n",
    "                disease_name = disease_mapping[folder_name.upper()][\"disease\"]\n",
    "                process_folder(folder_path, disease_name)\n",
    "\n",
    "# Call the function to process folders\n",
    "process_folders(main_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e75b8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the input folder (output folder from previous code)\n",
    "input_folder = \"Viral_Data_Csv\"\n",
    "output_folder = \"Padded_Viral_Data_Csv\"\n",
    "\n",
    "# Function to pad DNA sequences and save them to a new CSV file\n",
    "def pad_sequences_and_save(input_file_path, output_file_path, max_length):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file_path)\n",
    "\n",
    "    # Pad DNA sequences with 'N' characters\n",
    "    df['sequence'] = df['sequence'].apply(lambda x: x.ljust(max_length, 'N'))\n",
    "\n",
    "    # Remove the 'Length' field\n",
    "    df = df.drop(columns=['Length'])\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through each disease folder in the input folder\n",
    "for disease_folder in os.listdir(input_folder):\n",
    "    disease_folder_path = os.path.join(input_folder, disease_folder)\n",
    "    if os.path.isdir(disease_folder_path):\n",
    "        output_disease_folder = os.path.join(output_folder, disease_folder)\n",
    "        os.makedirs(output_disease_folder, exist_ok=True)\n",
    "        \n",
    "        # Iterate through each region subfolder in the disease folder\n",
    "        for region_folder in os.listdir(disease_folder_path):\n",
    "            region_folder_path = os.path.join(disease_folder_path, region_folder)\n",
    "            if os.path.isdir(region_folder_path):\n",
    "                output_subfolder = os.path.join(output_disease_folder, region_folder)\n",
    "                os.makedirs(output_subfolder, exist_ok=True)\n",
    "                \n",
    "                # Iterate through each CSV file in the region subfolder\n",
    "                for file_name in os.listdir(region_folder_path):\n",
    "                    if file_name.endswith(\".csv\"):\n",
    "                        input_file_path = os.path.join(region_folder_path, file_name)\n",
    "                        output_file_path = os.path.join(output_subfolder, file_name)\n",
    "\n",
    "                        # Read the CSV file to determine the maximum length\n",
    "                        df = pd.read_csv(input_file_path)\n",
    "                        max_length = df['sequence'].str.len().max()\n",
    "\n",
    "                        # Pad sequences and save to a new CSV file\n",
    "                        pad_sequences_and_save(input_file_path, output_file_path, max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da11539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets without headers\n",
    "train_df = pd.read_csv(\"fullset_train.csv\", header=None)\n",
    "validation_df = pd.read_csv(\"fullset_validation.csv\", header=None)\n",
    "test_df = pd.read_csv(\"fullset_test.csv\", header=None)\n",
    "\n",
    "# Calculate the length of the DNA sequence\n",
    "train_df['length'] = train_df[1].str.len()\n",
    "validation_df['length'] = validation_df[1].str.len()\n",
    "test_df['length'] = test_df[1].str.len()\n",
    "\n",
    "# Concatenate the datasets\n",
    "fullset_df = pd.concat([train_df, validation_df, test_df], ignore_index=True)\n",
    "\n",
    "# Save the concatenated dataset to a new CSV file\n",
    "fullset_df.to_csv(\"fullset_combined.csv\", index=False, header=False)  # Do not write headers\n",
    "\n",
    "# Load the concatenated dataset with the correct data types and column names\n",
    "fullset_df = pd.read_csv(\"fullset_combined.csv\", header=None, names=[\"sequence\", \"DNA\", \"Label\", \"length\"])\n",
    "  # Adjust filter condition based on your data\n",
    "\n",
    "# Save non-viral sequences to a new CSV file\n",
    "fullset_df.to_csv(\"non_viral_sequences.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de1edd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets without headers\n",
    "train_df = pd.read_csv(\"training_data_anella.csv\", header=None)\n",
    "test_df = pd.read_csv(\"test_data_anella.csv\", header=None)\n",
    "\n",
    "# Calculate the length of the DNA sequence\n",
    "train_df['length'] = train_df[1].str.len()\n",
    "test_df['length'] = test_df[1].str.len()\n",
    "\n",
    "# Concatenate the datasets\n",
    "fullset_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Save the concatenated dataset to a new CSV file\n",
    "fullset_df.to_csv(\"anella_viral.csv\", index=False, header=False)  # Do not write headers\n",
    "\n",
    "# Load the concatenated dataset with the correct data types and column names\n",
    "fullset_df = pd.read_csv(\"anella_viral.csv\", header=None, names=[\"sequence\", \"DNA\", \"Label\", \"length\"])\n",
    "  # Adjust filter condition based on your data\n",
    "\n",
    "# Save non-viral sequences to a new CSV file\n",
    "fullset_df.to_csv(\"anella_viral.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4296844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input folder (output folder from previous code)\n",
    "input_folder = \"Viral_Data_Csv\"\n",
    "output_folder = \"Padded_Viral_Data_Csv\"\n",
    "\n",
    "# Function to pad DNA sequences and save them to a new CSV file\n",
    "def pad_sequences_and_save(input_file_path, output_file_path, max_length):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file_path)\n",
    "\n",
    "    # Pad DNA sequences with 'N' characters\n",
    "    df['DNA'] = df['DNA'].apply(lambda x: x.ljust(max_length, 'N'))\n",
    "\n",
    "    # Remove the 'Length' field\n",
    "    df = df.drop(columns=['Length'])\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through each disease folder in the input folder\n",
    "for disease_folder in os.listdir(input_folder):\n",
    "    disease_folder_path = os.path.join(input_folder, disease_folder)\n",
    "    if os.path.isdir(disease_folder_path):\n",
    "        # Create the disease folder in the output folder\n",
    "        output_disease_folder = os.path.join(output_folder, disease_folder)\n",
    "        os.makedirs(output_disease_folder, exist_ok=True)\n",
    "        \n",
    "        # Iterate through each CSV file in the disease subfolder\n",
    "        for file_name in os.listdir(disease_folder_path):\n",
    "            if file_name.endswith(\".csv\"):\n",
    "                input_file_path = os.path.join(disease_folder_path, file_name)\n",
    "                \n",
    "                # Read the CSV file to determine the maximum length\n",
    "                df = pd.read_csv(input_file_path)\n",
    "                max_length = df['DNA'].str.len().max()\n",
    "                \n",
    "                # Construct the output file name with maximum length\n",
    "                output_file_name = os.path.splitext(file_name)[0] + f\"_{max_length}.csv\"\n",
    "                output_file_path = os.path.join(output_disease_folder, output_file_name)\n",
    "\n",
    "                # Pad sequences and save to a new CSV file\n",
    "                pad_sequences_and_save(input_file_path, output_file_path, max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "432a74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### INTEGER ENCODING\n",
    "\n",
    "input_folder = \"Padded_Viral_Data_Csv\"\n",
    "output_folder = \"Integer_Encoded_Viral_Data_Csv\"\n",
    "\n",
    "# Define nucleotide-to-integer mapping\n",
    "nucleotide_mapping = {'N': 0, 'A': 1, 'T': 2, 'C': 3, 'G': 4, 'n': 0, 'a': 1, 't': 2, 'c': 3, 'g': 4}\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# Function to perform integer encoding on a DNA sequence\n",
    "def integer_encode_sequence(sequence):\n",
    "    return [nucleotide_mapping[n] if n in nucleotide_mapping else 0 for n in sequence]\n",
    "\n",
    "# Function to perform integer encoding on a CSV file and save it\n",
    "def encode_and_save(input_file_path, output_file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    \n",
    "    # Integer encode the DNA sequences\n",
    "    df['DNA'] = df['DNA'].apply(integer_encode_sequence)\n",
    "    \n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Iterate through each CSV file in the input folder\n",
    "for disease_folder in os.listdir(input_folder):\n",
    "    disease_folder_path = os.path.join(input_folder, disease_folder)\n",
    "    if os.path.isdir(disease_folder_path):\n",
    "        output_disease_folder = os.path.join(output_folder, disease_folder)\n",
    "        os.makedirs(output_disease_folder, exist_ok=True)\n",
    "        # Iterate through each CSV file in the disease folder\n",
    "        for file_name in os.listdir(disease_folder_path):\n",
    "            if file_name.endswith(\".csv\"):\n",
    "                input_file_path = os.path.join(disease_folder_path, file_name)\n",
    "                output_file_path = os.path.join(output_disease_folder, file_name)\n",
    "                encode_and_save(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4f008b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### ONE-HAT ENCODING\n",
    "\n",
    "# Define the input and output folders\n",
    "input_folder = \"Padded_Viral_Data_Csv\"\n",
    "output_folder = \"OneHot_Encoded_Viral_Data_Csv\"\n",
    "\n",
    "# Define nucleotide-to-integer mapping\n",
    "nucleotide_mapping = {'N': 0, 'A': 1, 'T': 2, 'C': 3, 'G': 4, 'n': 0, 'a': 1, 't': 2, 'c': 3, 'g': 4}\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to perform one-hot encoding on a DNA sequence\n",
    "def one_hot_encode_sequence(sequence):\n",
    "    one_hot_encoding = [[0, 0, 0, 0, 0] for _ in range(len(sequence))]  # Initialize with zeros\n",
    "    for i, nucleotide in enumerate(sequence):\n",
    "        if nucleotide in nucleotide_mapping:\n",
    "            one_hot_encoding[i][nucleotide_mapping[nucleotide]] = 1  # Set the corresponding position to 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "# Function to perform one-hot encoding on a CSV file and save it\n",
    "def encode_and_save(input_file_path, output_file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    \n",
    "    # One-hot encode the DNA sequences\n",
    "    df['DNA'] = df['DNA'].apply(one_hot_encode_sequence)\n",
    "    \n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Iterate through each CSV file in the input folder\n",
    "for disease_folder in os.listdir(input_folder):\n",
    "    disease_folder_path = os.path.join(input_folder, disease_folder)\n",
    "    if os.path.isdir(disease_folder_path):\n",
    "        output_disease_folder = os.path.join(output_folder, disease_folder)\n",
    "        os.makedirs(output_disease_folder, exist_ok=True)\n",
    "        # Iterate through each CSV file in the disease folder\n",
    "        for file_name in os.listdir(disease_folder_path):\n",
    "            if file_name.endswith(\".csv\"):\n",
    "                input_file_path = os.path.join(disease_folder_path, file_name)\n",
    "                output_file_path = os.path.join(output_disease_folder, file_name)\n",
    "                encode_and_save(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c96a69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import product\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the input and output folders\n",
    "# input_folder = \"Padded_Viral_Data_Csv\"\n",
    "# output_folder = \"Kmer_Encoded_Viral_Data_Csv\"\n",
    "\n",
    "# # Define the value of k for k-mer encoding\n",
    "# k = 6\n",
    "\n",
    "# # Function to generate all possible k-mers of length k\n",
    "# def generate_kmers(k):\n",
    "#     return [''.join(kmer) for kmer in product('ACGTN', repeat=k)]\n",
    "\n",
    "# # Function to perform k-mer encoding on a DNA sequence\n",
    "# def kmer_encoding(sequence, k):\n",
    "#     kmers = generate_kmers(k)\n",
    "#     encoding = np.zeros(len(kmers))\n",
    "#     for i in range(len(sequence) - k + 1):\n",
    "#         kmer = sequence[i:i+k]\n",
    "#         if kmer in kmers:\n",
    "#             index = kmers.index(kmer)\n",
    "#             encoding[index] += 1\n",
    "#     return encoding\n",
    "\n",
    "# # Function to perform k-mer encoding on a CSV file and save it\n",
    "# def encode_and_save(input_file_path, output_file_path):\n",
    "#     # Read the CSV file\n",
    "#     df = pd.read_csv(input_file_path)\n",
    "    \n",
    "#     # Perform k-mer encoding on the DNA sequences\n",
    "#     encoded_sequences = []\n",
    "#     for sequence in df['DNA']:\n",
    "#         encoded_sequence = kmer_encoding(sequence, k)\n",
    "#         encoded_sequences.append(encoded_sequence)\n",
    "    \n",
    "#     # Create a DataFrame with the encoded sequences\n",
    "#     encoded_df = pd.DataFrame(encoded_sequences, columns=generate_kmers(k))\n",
    "    \n",
    "#     # Concatenate the encoded DataFrame with the original DataFrame\n",
    "#     df_encoded = pd.concat([df, encoded_df], axis=1)\n",
    "    \n",
    "#     # Save the updated DataFrame to a new CSV file\n",
    "#     df_encoded.to_csv(output_file_path, index=False)\n",
    "\n",
    "# # Create the output folder if it doesn't exist\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # Iterate through each CSV file in the input folder\n",
    "# for disease_folder in os.listdir(input_folder):\n",
    "#     disease_folder_path = os.path.join(input_folder, disease_folder)\n",
    "#     if os.path.isdir(disease_folder_path):\n",
    "#         output_disease_folder = os.path.join(output_folder, disease_folder)\n",
    "#         os.makedirs(output_disease_folder, exist_ok=True)\n",
    "#         # Iterate through each CSV file in the disease folder\n",
    "#         for file_name in os.listdir(disease_folder_path):\n",
    "#             if file_name.endswith(\".csv\"):\n",
    "#                 input_file_path = os.path.join(disease_folder_path, file_name)\n",
    "#                 output_file_path = os.path.join(output_disease_folder, file_name)\n",
    "#                 encode_and_save(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523e896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
